{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UnQWorkFlow - AI Video Generation Engine\n",
    "\n",
    "This notebook provides an automated pipeline for generating AI videos using the wan2.1 text-to-video model. \n",
    "\n",
    "## Features\n",
    "- Smart caching of the large model in Google Drive\n",
    "- Automatic code synchronization with GitHub\n",
    "- Idempotent design (can be run multiple times without unnecessary re-downloads)\n",
    "- Efficient dependency management\n",
    "\n",
    "**IMPORTANT**: To use this notebook, you need at least 15GB of free space in your Google Drive.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Initial Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "logger = logging.getLogger('unqworkflow')\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "GDRIVE_MOUNT_PATH = '/content/drive'\n",
    "GDRIVE_PROJECT_PATH = f'{GDRIVE_MOUNT_PATH}/MyDrive/UnQWorkFlow'\n",
    "REPO_PATH = f'{GDRIVE_PROJECT_PATH}/code'\n",
    "MODEL_PATH = f'{GDRIVE_PROJECT_PATH}/models/wan2.1'\n",
    "OUTPUT_PATH = f'{GDRIVE_PROJECT_PATH}/outputs'\n",
    "GITHUB_REPO_URL = 'https://github.com/Sandeepgaddam5432/unq-content-flow.git'\n",
    "# --- END CONFIGURATION ---\n",
    "\n",
    "# Print configuration for verification\n",
    "logger.info(\"Starting UnQWorkFlow Video Generator\")\n",
    "logger.info(f\"Google Drive Mount Path: {GDRIVE_MOUNT_PATH}\")\n",
    "logger.info(f\"Project Path: {GDRIVE_PROJECT_PATH}\")\n",
    "logger.info(f\"Repository Path: {REPO_PATH}\")\n",
    "logger.info(f\"Model Path: {MODEL_PATH}\")\n",
    "logger.info(f\"Output Path: {OUTPUT_PATH}\")\n",
    "\n",
    "# Create a timestamp to log the session\n",
    "session_start_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "logger.info(f\"Session started at: {session_start_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Mount Google Drive & Create Directory Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount(GDRIVE_MOUNT_PATH)\n",
    "logger.info(\"Google Drive mounted successfully.\")\n",
    "\n",
    "# Function to create directories if they don't exist\n",
    "def ensure_dir_exists(dir_path):\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "        logger.info(f\"Created directory: {dir_path}\")\n",
    "    else:\n",
    "        logger.info(f\"Directory already exists: {dir_path}\")\n",
    "\n",
    "# Create required directories\n",
    "ensure_dir_exists(GDRIVE_PROJECT_PATH)\n",
    "ensure_dir_exists(REPO_PATH)\n",
    "ensure_dir_exists(MODEL_PATH)\n",
    "ensure_dir_exists(OUTPUT_PATH)\n",
    "\n",
    "# Create additional directory for logs\n",
    "LOGS_PATH = f\"{GDRIVE_PROJECT_PATH}/logs\"\n",
    "ensure_dir_exists(LOGS_PATH)\n",
    "\n",
    "# Create a session log file\n",
    "session_id = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "session_log_file = f\"{LOGS_PATH}/session_{session_id}.log\"\n",
    "\n",
    "# Write initial session info\n",
    "with open(session_log_file, 'w') as f:\n",
    "    f.write(f\"UnQWorkFlow Session - {session_start_time}\\n\")\n",
    "    f.write(f\"Google Drive mounted at: {GDRIVE_MOUNT_PATH}\\n\")\n",
    "\n",
    "logger.info(f\"Session log created at: {session_log_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Sync GitHub Repository (Smart Clone/Pull Logic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import subprocess\n",
    "\n",
    "def run_command(cmd, cwd=None):\n",
    "    \"\"\"Run a shell command and return its output\"\"\"\n",
    "    result = subprocess.run(\n",
    "        cmd, \n",
    "        cwd=cwd, \n",
    "        shell=True, \n",
    "        check=True, \n",
    "        capture_output=True, \n",
    "        text=True\n",
    "    )\n",
    "    return result.stdout.strip()\n",
    "\n",
    "# Check if repo exists and sync accordingly\n",
    "if os.path.exists(os.path.join(REPO_PATH, '.git')):\n",
    "    # Repository exists, pull latest changes\n",
    "    logger.info(f\"Repository exists at {REPO_PATH}. Pulling latest changes...\")\n",
    "    try:\n",
    "        output = run_command(\"git pull\", cwd=REPO_PATH)\n",
    "        logger.info(f\"Git pull output: {output}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        logger.error(f\"Git pull failed: {e}\")\n",
    "        # Handle potential conflicts\n",
    "        logger.warning(\"Attempting to reset and pull...\")\n",
    "        run_command(\"git fetch origin\", cwd=REPO_PATH)\n",
    "        run_command(\"git reset --hard origin/main\", cwd=REPO_PATH)\n",
    "        logger.info(\"Repository reset to main branch head\")\n",
    "else:\n",
    "    # Repository doesn't exist, clone it\n",
    "    logger.info(f\"Repository doesn't exist at {REPO_PATH}. Cloning from {GITHUB_REPO_URL}...\")\n",
    "    \n",
    "    # First, ensure the directory is empty or doesn't exist\n",
    "    if os.path.exists(REPO_PATH):\n",
    "        # If it exists but is not a git repo, clean it\n",
    "        shutil.rmtree(REPO_PATH)\n",
    "        os.makedirs(REPO_PATH)\n",
    "    \n",
    "    try:\n",
    "        output = run_command(f\"git clone {GITHUB_REPO_URL} {REPO_PATH}\")\n",
    "        logger.info(f\"Git clone output: {output}\")\n",
    "        logger.info(f\"Repository cloned successfully to {REPO_PATH}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        logger.error(f\"Git clone failed: {e}\")\n",
    "        raise\n",
    "\n",
    "# Verify the repo is properly synced\n",
    "repo_files = os.listdir(REPO_PATH)\n",
    "logger.info(f\"Repository contains {len(repo_files)} files/directories\")\n",
    "if 'requirements.txt' in repo_files:\n",
    "    logger.info(\"Found requirements.txt in the repository\")\n",
    "else:\n",
    "    logger.warning(\"requirements.txt not found in the repository!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Install Dependencies (Efficiently)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Function to install dependencies from requirements.txt\n",
    "def install_requirements(requirements_path):\n",
    "    if os.path.exists(requirements_path):\n",
    "        logger.info(f\"Installing dependencies from {requirements_path}...\")\n",
    "        try:\n",
    "            # Install dependencies\n",
    "            !pip install -q -r {requirements_path}\n",
    "            logger.info(\"Dependencies installed successfully\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to install dependencies: {e}\")\n",
    "            return False\n",
    "    else:\n",
    "        logger.error(f\"Requirements file not found at {requirements_path}\")\n",
    "        return False\n",
    "\n",
    "# Path to requirements.txt in the repo\n",
    "requirements_path = os.path.join(REPO_PATH, 'requirements.txt')\n",
    "\n",
    "# Install dependencies\n",
    "install_success = install_requirements(requirements_path)\n",
    "\n",
    "if not install_success:\n",
    "    logger.warning(\"Installing fallback dependencies...\")\n",
    "    \n",
    "    # Install core dependencies directly if requirements.txt fails\n",
    "    !pip install -q torch torchvision torchaudio transformers diffusers accelerate\n",
    "    !pip install -q opencv-python moviepy ffmpeg-python\n",
    "    !pip install -q numpy scipy pillow tqdm requests\n",
    "    \n",
    "    logger.info(\"Fallback dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Smart Model Caching (The Key Optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import time\n",
    "import requests\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Define the key file that indicates the model is fully downloaded\n",
    "MODEL_KEY_FILE = os.path.join(MODEL_PATH, 'model.safetensors')\n",
    "\n",
    "# Function to check if model is already downloaded\n",
    "def check_model_downloaded():\n",
    "    if os.path.exists(MODEL_KEY_FILE):\n",
    "        file_size_mb = os.path.getsize(MODEL_KEY_FILE) / (1024 * 1024)  # Size in MB\n",
    "        logger.info(f\"Model found in Google Drive. Size: {file_size_mb:.2f} MB\")\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Function to download the model using Hugging Face or another source\n",
    "def download_model():\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        logger.info(\"Starting model download. This might take a while...\")\n",
    "        \n",
    "        # For wan2.1 model, we'll use the Hugging Face transformers library\n",
    "        # This is a placeholder - you should replace with the actual model download code\n",
    "        import torch\n",
    "        from diffusers import DiffusionPipeline, DPMSolverMultistepScheduler\n",
    "        \n",
    "        # Note: The actual model ID may differ - replace with correct one\n",
    "        model_id = \"wanonly/wan2.1\"  # Example - verify the correct model ID\n",
    "        \n",
    "        # Download the model directly to the MODEL_PATH\n",
    "        pipe = DiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
    "        pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "        pipe.enable_xformers_memory_efficient_attention()\n",
    "        \n",
    "        # Save the model to our MODEL_PATH\n",
    "        pipe.save_pretrained(MODEL_PATH)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        logger.info(f\"Model downloaded and saved successfully to {MODEL_PATH}\")\n",
    "        logger.info(f\"Download took {(end_time - start_time) / 60:.2f} minutes\")\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Model download failed: {e}\")\n",
    "        return False\n",
    "\n",
    "# Main logic for model management\n",
    "if check_model_downloaded():\n",
    "    logger.info(\"Model already exists in Google Drive. Skipping download.\")\n",
    "else:\n",
    "    logger.info(\"Model not found in Google Drive. Starting download...\")\n",
    "    success = download_model()\n",
    "    \n",
    "    if success:\n",
    "        logger.info(\"Model download completed successfully.\")\n",
    "    else:\n",
    "        logger.error(\"Failed to download the model. Please check logs and try again.\")\n",
    "        # You might want to halt execution here if the model is essential\n",
    "        # raise Exception(\"Model download failed, cannot continue.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: The Main Video Generation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def generate_video(prompt: str, duration_seconds: int, output_filename: str) -> dict:\n",
    "    \"\"\"\n",
    "    Generates a video using the wan2.1 model.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The text prompt for the video.\n",
    "        duration_seconds (int): The desired duration of the video.\n",
    "        output_filename (str): The name for the output video file (e.g., 'space_video_1.mp4').\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and the full path to the generated video.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info(f\"Starting video generation for prompt: {prompt}\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Ensure the output directory exists\n",
    "        ensure_dir_exists(OUTPUT_PATH)\n",
    "        \n",
    "        # Prepare output path\n",
    "        final_video_path = os.path.join(OUTPUT_PATH, output_filename)\n",
    "        \n",
    "        # 1. Load the wan2.1 model from MODEL_PATH\n",
    "        logger.info(\"Loading the model...\")\n",
    "        import torch\n",
    "        from diffusers import DiffusionPipeline, DPMSolverMultistepScheduler\n",
    "        \n",
    "        # Calculate number of frames based on duration (assuming 30fps)\n",
    "        fps = 30\n",
    "        num_frames = duration_seconds * fps\n",
    "        \n",
    "        # Load the pipeline\n",
    "        pipe = DiffusionPipeline.from_pretrained(\n",
    "            MODEL_PATH, \n",
    "            torch_dtype=torch.float16\n",
    "        )\n",
    "        \n",
    "        # Move the model to GPU if available\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        logger.info(f\"Using device: {device}\")\n",
    "        pipe = pipe.to(device)\n",
    "        \n",
    "        # Set up the scheduler for better quality\n",
    "        pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "        \n",
    "        # Optimize memory usage if possible\n",
    "        if hasattr(pipe, 'enable_xformers_memory_efficient_attention'):\n",
    "            pipe.enable_xformers_memory_efficient_attention()\n",
    "        \n",
    "        # 2. Execute the text-to-video generation process\n",
    "        logger.info(\"Generating video frames...\")\n",
    "        \n",
    "        # Generate the video frames (note: actual API might differ)\n",
    "        result = pipe(\n",
    "            prompt=prompt,\n",
    "            num_frames=num_frames,\n",
    "            guidance_scale=7.5,  # You may tune this parameter\n",
    "            num_inference_steps=50,  # You may tune this parameter\n",
    "            height=320,  # Adjust based on model capabilities\n",
    "            width=576    # Adjust based on model capabilities\n",
    "        ).frames\n",
    "        \n",
    "        # 3. Save the final video to the OUTPUT_PATH\n",
    "        logger.info(f\"Processing and saving video to {final_video_path}...\")\n",
    "        \n",
    "        # Convert frames to video using moviepy or opencv\n",
    "        import cv2\n",
    "        import numpy as np\n",
    "        \n",
    "        # Create a VideoWriter object\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(final_video_path, fourcc, fps, (576, 320))\n",
    "        \n",
    "        # Write all frames to the video file\n",
    "        for frame in result:\n",
    "            # Convert PIL Image to OpenCV format\n",
    "            frame_np = np.array(frame)\n",
    "            # Convert RGB to BGR (OpenCV uses BGR)\n",
    "            frame_bgr = cv2.cvtColor(frame_np, cv2.COLOR_RGB2BGR)\n",
    "            out.write(frame_bgr)\n",
    "        \n",
    "        # Release the VideoWriter\n",
    "        out.release()\n",
    "        \n",
    "        end_time = time.time()\n",
    "        generation_time = (end_time - start_time) / 60  # time in minutes\n",
    "        \n",
    "        logger.info(f\"Video generated successfully in {generation_time:.2f} minutes: {final_video_path}\")\n",
    "        \n",
    "        # Record the generation in the session log\n",
    "        with open(session_log_file, 'a') as f:\n",
    "            f.write(f\"\\nVideo generated at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "            f.write(f\"Prompt: {prompt}\\n\")\n",
    "            f.write(f\"Duration: {duration_seconds} seconds\\n\")\n",
    "            f.write(f\"Output file: {output_filename}\\n\")\n",
    "            f.write(f\"Generation time: {generation_time:.2f} minutes\\n\")\n",
    "        \n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"video_path\": final_video_path,\n",
    "            \"generation_time_minutes\": generation_time,\n",
    "            \"prompt\": prompt,\n",
    "            \"duration\": duration_seconds\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during video generation: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        return {\n",
    "            \"status\": \"error\",\n",
    "            \"message\": str(e),\n",
    "            \"prompt\": prompt\n",
    "        }\n",
    "\n",
    "# Example of how to call the function (uncomment to test)\n",
    "# result = generate_video(\n",
    "#     prompt=\"A cinematic shot of a rocket launching into space, with flames and smoke billowing from the engines\",\n",
    "#     duration_seconds=10,\n",
    "#     output_filename=\"rocket_launch_demo.mp4\"\n",
    "# )\n",
    "# print(json.dumps(result, indent=2))  # Print result as a formatted JSON string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: API Integration Example\n",
    "\n",
    "This cell demonstrates how the notebook could be integrated with the UnQWorkFlow application. It sets up a simple API endpoint that the main application can call to generate videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from IPython.display import HTML, display\n",
    "import ipywidgets as widgets\n",
    "import threading\n",
    "\n",
    "# Create a simple UI for testing the video generation\n",
    "prompt_input = widgets.Textarea(\n",
    "    value='A cinematic shot of a rocket launching into space',\n",
    "    placeholder='Enter your video prompt here',\n",
    "    description='Prompt:',\n",
    "    disabled=False,\n",
    "    layout=widgets.Layout(width='90%', height='80px')\n",
    ")\n",
    "\n",
    "duration_input = widgets.IntSlider(\n",
    "    value=5,\n",
    "    min=3,\n",
    "    max=30,\n",
    "    step=1,\n",
    "    description='Duration (s):',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True\n",
    ")\n",
    "\n",
    "filename_input = widgets.Text(\n",
    "    value='generated_video.mp4',\n",
    "    placeholder='output.mp4',\n",
    "    description='Filename:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "output = widgets.Output()\n",
    "button = widgets.Button(description=\"Generate Video\")\n",
    "progress = widgets.FloatProgress(value=0, min=0, max=100, description='Processing:')\n",
    "\n",
    "def on_button_click(b):\n",
    "    output.clear_output()\n",
    "    with output:\n",
    "        progress.value = 0\n",
    "        display(progress)\n",
    "        \n",
    "        # Start a thread to show progress\n",
    "        def update_progress():\n",
    "            import time\n",
    "            import random\n",
    "            # Simulate progress\n",
    "            while progress.value < 99:\n",
    "                time.sleep(0.5)\n",
    "                # Randomly increment progress to simulate processing\n",
    "                if progress.value < 30:\n",
    "                    progress.value += random.uniform(0.5, 2)\n",
    "                elif progress.value < 70:\n",
    "                    progress.value += random.uniform(0.1, 0.8)\n",
    "                else:\n",
    "                    progress.value += random.uniform(0.05, 0.2)\n",
    "        \n",
    "        progress_thread = threading.Thread(target=update_progress)\n",
    "        progress_thread.daemon = True\n",
    "        progress_thread.start()\n",
    "        \n",
    "        # Call the actual generation function\n",
    "        print(f\"Generating video for prompt: {prompt_input.value}\")\n",
    "        print(f\"Duration: {duration_input.value} seconds\")\n",
    "        print(f\"Filename: {filename_input.value}\")\n",
    "        print(\"\\nThis may take several minutes. Please wait...\")\n",
    "        \n",
    "        result = generate_video(\n",
    "            prompt=prompt_input.value,\n",
    "            duration_seconds=duration_input.value,\n",
    "            output_filename=filename_input.value\n",
    "        )\n",
    "        \n",
    "        progress.value = 100\n",
    "        \n",
    "        if result[\"status\"] == \"success\":\n",
    "            print(f\"\\n‚úÖ Video generated successfully!\")\n",
    "            print(f\"üìÇ Path: {result['video_path']}\")\n",
    "            print(f\"‚è±Ô∏è Generation time: {result['generation_time_minutes']:.2f} minutes\")\n",
    "            \n",
    "            # Display the video if possible\n",
    "            try:\n",
    "                video_path = result['video_path'].replace('/content/', '/content/drive/')\n",
    "                display(HTML(f\"\"\"\n",
    "                <div style=\"border:2px solid #ddd; padding:10px; border-radius:10px; margin-top:20px;\">\n",
    "                  <h3 style=\"margin-top:0\">Generated Video Preview</h3>\n",
    "                  <video width=\"100%\" height=\"auto\" controls>\n",
    "                    <source src=\"{video_path}\" type=\"video/mp4\">\n",
    "                    Your browser does not support the video tag.\n",
    "                  </video>\n",
    "                </div>\n",
    "                \"\"\"))\n",
    "            except Exception as e:\n",
    "                print(f\"Could not display video preview: {e}\")\n",
    "                \n",
    "        else:\n",
    "            print(f\"\\n‚ùå Error: {result['message']}\")\n",
    "\n",
    "button.on_click(on_button_click)\n",
    "\n",
    "# Display the UI\n",
    "display(widgets.HTML(\"<h2>UnQWorkFlow Video Generator</h2>\"))\n",
    "display(prompt_input)\n",
    "display(widgets.HBox([duration_input, filename_input]))\n",
    "display(button)\n",
    "display(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8: Session Summary and Cleanup\n",
    "\n",
    "This cell provides a summary of the current session and handles any necessary cleanup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Calculate the session duration\n",
    "session_end_time = datetime.now()\n",
    "session_start_time_dt = datetime.strptime(session_start_time, '%Y-%m-%d %H:%M:%S')\n",
    "session_duration = session_end_time - session_start_time_dt\n",
    "\n",
    "logger.info(\"\\nSession Summary:\")\n",
    "logger.info(f\"Session started at: {session_start_time}\")\n",
    "logger.info(f\"Session ended at: {session_end_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "logger.info(f\"Session duration: {session_duration}\")\n",
    "\n",
    "# Write session summary to the log file\n",
    "with open(session_log_file, 'a') as f:\n",
    "    f.write(f\"\\nSession ended at: {session_end_time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    f.write(f\"Session duration: {session_duration}\\n\")\n",
    "\n",
    "# Display session info\n",
    "print(\"\\nSession Information:\")\n",
    "print(f\"Session ID: {session_id}\")\n",
    "print(f\"Duration: {session_duration}\")\n",
    "print(f\"Log file: {session_log_file}\")\n",
    "\n",
    "# Optional cleanup to free memory\n",
    "import gc\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(\"\\nUnQWorkFlow video generation session completed.\")\n",
    "print(\"The notebook is now ready for the next generation task.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Launch the Backend Server & Cloudflare Tunnel\n",
    "\n",
    "This section sets up a Flask web server and exposes it to the internet using a Cloudflare Tunnel. This allows the frontend application to communicate directly with this notebook in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Cell: Download Cloudflared\n",
    "!wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O cloudflared\n",
    "!chmod +x cloudflared\n",
    "print(\"üöÄ Cloudflared client downloaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Cell: Create and Run Flask API Server\n",
    "from flask import Flask, request, jsonify\n",
    "import threading\n",
    "import subprocess\n",
    "import re\n",
    "import time\n",
    "from flask_cors import CORS\n",
    "\n",
    "# --- 1. Define the Flask App ---\n",
    "app = Flask(__name__)\n",
    "CORS(app)  # Enable CORS for all routes\n",
    "\n",
    "@app.route('/api/generate-video', methods=['POST'])\n",
    "def handle_video_generation():\n",
    "    print(\"Received request at /api/generate-video\")\n",
    "    data = request.get_json()\n",
    "    if not data or 'prompt' not in data:\n",
    "        return jsonify({\"status\": \"error\", \"message\": \"Missing 'prompt' in request\"}), 400\n",
    "\n",
    "    prompt = data.get('prompt')\n",
    "    duration = data.get('duration', 15) # Default duration 15s\n",
    "    job_id = f\"job_{int(time.time())}\" # Create a simple job ID\n",
    "    output_filename = f\"{job_id}.mp4\"\n",
    "\n",
    "    # Call our existing video generation function\n",
    "    result = generate_video(prompt=prompt, duration_seconds=duration, output_filename=output_filename)\n",
    "\n",
    "    # Make the output file path accessible via a relative URL\n",
    "    if result[\"status\"] == \"success\":\n",
    "        # Add a URL that can be accessed through the Flask server\n",
    "        result[\"video_url\"] = f\"/api/videos/{output_filename}\"\n",
    "    \n",
    "    return jsonify(result)\n",
    "\n",
    "@app.route('/api/videos/<filename>', methods=['GET'])\n",
    "def serve_video(filename):\n",
    "    # Basic validation to prevent directory traversal attacks\n",
    "    if '../' in filename or '/' in filename:\n",
    "        return jsonify({\"error\": \"Invalid filename\"}), 400\n",
    "        \n",
    "    video_path = os.path.join(OUTPUT_PATH, filename)\n",
    "    if not os.path.exists(video_path):\n",
    "        return jsonify({\"error\": \"Video not found\"}), 404\n",
    "        \n",
    "    # In a real production environment, you'd use send_file here\n",
    "    # For the Colab environment, we'll return the full path for now\n",
    "    return jsonify({\"video_path\": video_path})\n",
    "\n",
    "@app.route('/api/health', methods=['GET'])\n",
    "def health_check():\n",
    "    return jsonify({\n",
    "        \"status\": \"online\",\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"model\": \"wan2.1\",\n",
    "        \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    })\n",
    "\n",
    "# --- 2. Function to Run Flask App ---\n",
    "def run_flask():\n",
    "    # Running on port 5000, accessible only within Colab\n",
    "    app.run(port=5000, host='0.0.0.0')\n",
    "\n",
    "# --- 3. Function to Run Cloudflare Tunnel ---\n",
    "def run_cloudflared():\n",
    "    # Start the cloudflared tunnel\n",
    "    process = subprocess.Popen(\n",
    "        ['./cloudflared', 'tunnel', '--url', 'http://localhost:5000'],\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE,\n",
    "        text=True\n",
    "    )\n",
    "    \n",
    "    # Find the public URL in the output\n",
    "    for line in iter(process.stderr.readline, ''):\n",
    "        if '.trycloudflare.com' in line:\n",
    "            public_url = re.search(r'(https?://[a-zA-Z0-9-]+\\.trycloudflare\\.com)', line).group(0)\n",
    "            print(\"=====================================================================================\")\n",
    "            print(f\"üöÄ Your Public Backend URL is LIVE: {public_url}\")\n",
    "            print(\"COPY THIS URL and PASTE it into the UnQWorkFlow website.\")\n",
    "            print(\"=====================================================================================\")\n",
    "            break\n",
    "\n",
    "# --- 4. Start Both in Threads ---\n",
    "print(\"Starting Flask server in the background...\")\n",
    "flask_thread = threading.Thread(target=run_flask)\n",
    "flask_thread.daemon = True\n",
    "flask_thread.start()\n",
    "\n",
    "print(\"Starting Cloudflare Tunnel...\")\n",
    "time.sleep(2) # Give Flask a moment to start\n",
    "cloudflared_thread = threading.Thread(target=run_cloudflared)\n",
    "cloudflared_thread.daemon = True\n",
    "cloudflared_thread.start()\n",
    "\n",
    "# Keep the main thread alive to see the output\n",
    "print(\"Waiting for Cloudflare tunnel to be established...\")\n",
    "cloudflared_thread.join()\n",
    "\n",
    "# This line will only be reached if the cloudflared thread terminates\n",
    "print(\"\\n‚ö†Ô∏è The Cloudflare tunnel has terminated. Please restart the notebook if you need to reconnect.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
